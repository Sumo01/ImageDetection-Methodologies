{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks (CNNs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">*Reference:*   \n",
    "https://towardsdatascience.com/a-beginners-guide-to-convolutional-neural-networks-cnns-14649dbddce8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Convolution:**  \n",
    "Convolution is a fundamental operation in image processing and signal processing. It involves combining two functions to produce a third function that represents how one function affects the other. In the context of image processing, convolution is often used to process images by applying a filter or kernel to the image pixels.  \n",
    "> It is how the input is modified by a filter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In convolutional networks, multiple filters are taken to slice through the image and map them one by one and learn different portions of an input image. For example, the dark edges of an image are mapped onto a blank image using a convolution. The network then learns how to identify a dark edge using this mapping and filter."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; flex-wrap: wrap; justify-content: center;\">\n",
    "    <figure style=\"margin: 10px;\">\n",
    "        <img src=\"./Images/CNN1.png\" alt=\"Dark Edge Mapping using a Convolution\" style=\"width: auto-width; height: auto-height; object-fit: cover;\">\n",
    "        <figcaption style=\"justify-content:center;\">Dark Edge Mapping using a Convolution</figcaption>\n",
    "    </figure>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How Convolution Works:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution can be done in 2D or in 3D. When the input image is in grayscale then the image has only 2 channels and hence we perform 2D convolution. However, if the image is in RGB, the image has three channels - red, blue and green. Here, we perform 3D convolution or 2D convolution three times, for each colour channel separately.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution filters are usually 3 x 3 matrices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; flex-wrap: wrap; justify-content: center;\">\n",
    "    <figure style=\"margin: 10px;\">\n",
    "        <img src=\"./Images/CNN2.png\" alt=\"2D Convolution\" style=\"width: auto-width; height: auto-height; object-fit: cover;\">\n",
    "        <figcaption style=\"justify-content:center;\">2D Convolution</figcaption>\n",
    "    </figure>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the above image. We have the following:\n",
    "> *Input Image:* 4x4 2D image without any padding.   \n",
    "> *Convolution Filter:*  3x3 filter  \n",
    "> *Output Image:* 2x2 image  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the terminologies used:\n",
    "> *Padding:*   \n",
    "Padding is the process of adding additional noise to the edges of an image. This is to mitigate loss and preserve spatial information.  \n",
    "> *Stride:*   \n",
    "Stride refers to the number of columns/rows by which the filter will move."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Process of Applying the Filter:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The filter is first mapped to the first 3 x 3 matrix in the input image. This is from [0,0]- [2,2]. Here that is: \n",
    "<div style=\"display: flex; flex-wrap: wrap; justify-content: center;\">\n",
    "    <figure style=\"margin: 10px;\">\n",
    "        <img src=\"./Images/CNN3.png\" alt=\"\" style=\"width: auto-width; height: auto-height; object-fit: cover;\">\n",
    "        <figcaption style=\"justify-content:center;\"></figcaption>\n",
    "    </figure>\n",
    "</div>\n",
    "\n",
    "2. Once mapped, the values at the respective positions are multiplied with each other and then all the products are added. That would be:\n",
    "\n",
    "$$ (2 * 1) + (0 * 0) + (1 * 1) + (0 * 0) + (1 * 0) + (0 * 0) + (0 * 0) + (0 * 1) + (1 * 0) = 3 $$\n",
    "\n",
    "3. This value obtained here is the filtered value of the first 3X3 pixel of the input image. The same is put into the [0,0] cell of the output image.\n",
    "\n",
    "4. Then move the filter to the right/left/up/down by the stride decided upon. Repeat the above steps until all the columns and rows of the input matrix has been covered and the final output matrix is filled.\n",
    "\n",
    "The output we obtain here is:\n",
    "<div style=\"display: flex; flex-wrap: wrap; justify-content: center;\">\n",
    "    <figure style=\"margin: 10px;\">\n",
    "        <img src=\"./Images/CNN4.png\" alt=\"\" style=\"width: auto-width; height: auto-height; object-fit: cover;\">\n",
    "        <figcaption style=\"justify-content:center;\"></figcaption>\n",
    "    </figure>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above process is for a 2D image - that is an image in grayscale. The same process is applied when it comes to a coloured image - except it is done three times. Once for the red channel, once for the blue and once for the green. At the end the output images for all three channels are combined to obtain the final output image. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relu Activation Function:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Reference:*  \n",
    "https://builtin.com/machine-learning/relu-activation-function  \n",
    "https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rectified linear activation function or ReLU for short is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero. It has become the default activation function for many types of neural networks because a model that uses it is easier to train and often achieves better performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pooling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pooling is the methodology used to reduce the x and y dimensions of a 3d image. It is similar to convolution. Convolution is usually used to reduce the y dimension of the image. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two types of pooling that are commonly used:\n",
    "1. Max pooling -  Maximum value is taken across the filter window\n",
    "2. Average pooling - Average value is taken"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Common CNN Architecture:\n",
    "\n",
    "<div style=\"display: flex; flex-wrap: wrap; justify-content: center;\">\n",
    "    <figure style=\"margin: 10px;\">\n",
    "        <img src=\"./Images/CNN5.png\" alt=\"\" style=\"width: auto-width; height: auto-height; object-fit: cover;\">\n",
    "        <figcaption></figcaption>\n",
    "    </figure>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it comes to the implementation of CNNs, the most successful architectures use one or more stacks of convolution + pool layers with Relu activation followed by a flatten and then dense layer"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
